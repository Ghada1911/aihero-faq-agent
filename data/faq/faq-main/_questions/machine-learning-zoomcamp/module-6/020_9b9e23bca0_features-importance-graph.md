---
id: 9b9e23bca0
question: Features Importance graph
sort_order: 20
---

I like this visual implementation of features importance in scikit-learn library:

[https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)

It adds standard errors to features importance, allowing you to trace the stability of features—important for a model’s explainability—over different parameters of the model.